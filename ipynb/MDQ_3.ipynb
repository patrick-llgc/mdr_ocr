{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing for OCR\n",
    "This ipython notebook covers the possibilities to preprocess scanned medical documents to be used with OCR software such as Tesseract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "%matplotlib inline\n",
    "print(\"OpenCV Version : %s \" % cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate(image, angle, scale=1.0):\n",
    "    \"\"\"Rotate image by angle and scale.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    center = (w//2, h//2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    \n",
    "    # fill in 255 (white) as border during rotation\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), borderValue=255)\n",
    "    return rotated\n",
    "\n",
    "def pad(image, h_margin=100, w_margin=100):\n",
    "    \"\"\"Pad 2D image by `margin` pixels on four sides.\n",
    "    \"\"\"\n",
    "    assert len(image.shape) == 2, 'Image is not 2D!'\n",
    "    h, w = image.shape\n",
    "    padded = np.ones((h + 2 * h_margin, w + 2 * w_margin), dtype='uint8') * 255\n",
    "    padded[h_margin : (h_margin + h), w_margin : (w_margin + w)] = image\n",
    "    return padded\n",
    "\n",
    "def order_points(pts):\n",
    "    \"\"\"Reorder an array of 4 coordinates.\n",
    "\n",
    "    The reordered list is in the order of top-left, top-right, \n",
    "    bottom-right, and bottom-left.\n",
    "    \"\"\"\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # the top-right point will have the smallest difference\n",
    "    # the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    \"\"\"Perspective transformation a region of interest in image.\n",
    "    \"\"\"\n",
    "\n",
    "    # reorder the points first\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # construct destination canvas\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped\n",
    "\n",
    "def box_height(box):\n",
    "    \"\"\"Find the height of a bounding box.\n",
    "    \n",
    "    Input `box` contains the coordinates of four corner points of the box.\n",
    "    \"\"\"\n",
    "    points = order_points(box)\n",
    "    height = ((points[0][0] - points[-1][0])**2 +  (points[0][1] - points[-1][1])**2)**0.5\n",
    "    return height\n",
    "\n",
    "def box_aspect_ratio(box):\n",
    "    \"\"\"Find the aspect ratio of a bounding box.\n",
    "    \n",
    "    Input `box` contains the coordinates of four corner points of the box.\n",
    "    \"\"\"\n",
    "    points = order_points(box)\n",
    "    height = ((points[0][0] - points[-1][0])**2 +  (points[0][1] - points[-1][1])**2)**0.5\n",
    "    width = ((points[0][0] - points[1][0])**2 +  (points[0][1] - points[1][1])**2)**0.5\n",
    "    aspect_ratio = height * 1. / width\n",
    "    return aspect_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = [r'./testImages/1000992520057_3007_1.jpg',\n",
    "             r'./testImages/1000995056687_3007_1.jpg',\n",
    "             r'./testImages/1000967244029_3007_1.jpg',\n",
    "             r'./testImages/1000968571699_3007_2.jpg',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image, convert to gray scale and apply thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(filenames[0])\n",
    "\n",
    "# convert to gray scale and visualize\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "matplotlib.rcParams['figure.figsize'] = (5.0, 10.0) \n",
    "plt.imshow(gray, cmap='gray')\n",
    "\n",
    "# # Note: unfortunately equalization of histogram does not work with document images!\n",
    "# equ = cv2.equalizeHist(gray)\n",
    "# plt.imshow(np.hstack((gray, equ)), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a combination of global and adaptive thresholding gives the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Combination of global thresholding...\n",
    "(T, thresh1) = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "# plt.imshow(thresh1, cmap='gray')\n",
    "\n",
    "# And adaptive thresholding!\n",
    "thresh2 = cv2.adaptiveThreshold(gray, 255, \n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 9)\n",
    "# plt.imshow(thresh2, cmap='gray')\n",
    "\n",
    "# bitwise OR heltps to clean up artifacts at the boundaries\n",
    "thresh3 = cv2.bitwise_or(thresh1, thresh2)\n",
    "matplotlib.rcParams['figure.figsize'] = (60.0, 30.0) \n",
    "plt.imshow(np.hstack((thresh1, thresh2, thresh3)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-round process\n",
    "\n",
    "First round performs box detection directly on the preprocessed binary image. This would normally get pretty good result. However if the scanning quality is poor, we use the first round to perform a clean-up of borders and do a second round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = thresh3.copy()\n",
    "# inversion to make characters non-zero\n",
    "image = 255 - thresh\n",
    "\n",
    "# morph\n",
    "struct_elem = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 1))\n",
    "image = cv2.dilate(image.copy(), struct_elem, iterations=2)\n",
    "\n",
    "# find contours\n",
    "im2, cnts, hierarchy = cv2.findContours(image.copy().astype(np.uint8), \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = [cnt for cnt in cnts if cv2.contourArea(cnt) > 1400]\n",
    "\n",
    "# compute and draw bounding box\n",
    "canvas = thresh.copy()\n",
    "c = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "boxes = []\n",
    "for i in range(len(c)):\n",
    "    rect = cv2.minAreaRect(c[i])\n",
    "    box = np.int0(cv2.boxPoints(rect))\n",
    "    boxes.append(box)\n",
    "    cv2.drawContours(canvas, [box], -1, 0, 3)\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 20.0) \n",
    "plt.imshow(canvas, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we inspect the statistics of the box locations, which gives us good information regarding font size, left border, right border, rotation angle (if the texts are tilted), etc.\n",
    "\n",
    "Second round find the most popular left and right boundaries of bounding boxes, and then crop the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = []\n",
    "lefts = []\n",
    "rights = []\n",
    "tops = []\n",
    "bottoms = []\n",
    "angles = []\n",
    "for box in boxes:\n",
    "    points = order_points(box)\n",
    "    height = ((points[0][0] - points[-1][0])**2 +  (points[0][1] - points[-1][1])**2)**0.5\n",
    "    heights.append(height)\n",
    "    angle = np.arctan((points[1][1] - points[0][1])* 1.0 / (points[1][0] - points[0][0])) / 3.14 * 180\n",
    "    angles.append(angle)\n",
    "    lefts.append(points[0][0])\n",
    "    rights.append(points[2][0])\n",
    "    tops.append(points[0][1])\n",
    "    bottoms.append(points[2][1])\n",
    "\n",
    "# the median height of the bounding boxes is the fontsize in pixels\n",
    "fontsize = int(np.median(heights))\n",
    "rotate_angle = np.median(angles)\n",
    "print('Font size is {} pixels.'.format(fontsize))\n",
    "print('Rotate {:.2f} degrees counterclockwise to correct text tilt.'.format(rotate_angle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessed image: this can be fed into tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lefts = sorted(lefts)\n",
    "n_neighbors = [np.sum(np.abs(lefts[idx:idx+10] - lefts[idx]) < 10) for idx in range(len(lefts))]\n",
    "idx = np.argmax(n_neighbors)\n",
    "left_border = int(lefts[idx])\n",
    "\n",
    "rights = sorted(rights)\n",
    "n_neighbors = [np.sum(np.abs(rights[idx:idx+10] - rights[idx]) < 10) for idx in range(len(rights))]\n",
    "idx = np.argmax(n_neighbors)\n",
    "if (idx + 10) < len(rights):\n",
    "    right_border = int(rights[idx+10])\n",
    "else:\n",
    "    right_border = canvas.shape[1] - 1\n",
    "\n",
    "top_border = max(min(tops), 0)\n",
    "bottom_border = max(bottoms)\n",
    "print('Left {}, Right {}, Top {}, Bottom {}'.format(left_border, right_border, top_border, bottom_border))\n",
    "cropped = thresh3[:, left_border:right_border]\n",
    "\n",
    "# pad documents for visualization\n",
    "cropped = pad(cropped)\n",
    "plt.imshow(cropped, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or, alternatively, we can draw boxes with openCV directly\n",
    "\n",
    "We can draw the bounding boxes with openCV and feed tesseract with each extracted box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# inversion to make characters non-zero\n",
    "image = rotate(cropped, rotate_angle)\n",
    "clean_canvas = image.copy()\n",
    "canvas = clean_canvas.copy()\n",
    "\n",
    "image = 255 - image\n",
    "\n",
    "# morph\n",
    "struct_elem = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 1))\n",
    "image = cv2.dilate(image.copy(), struct_elem, iterations=2)\n",
    "\n",
    "# find contours\n",
    "im2, cnts, hierarchy = cv2.findContours(image.copy().astype(np.uint8), \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = [cnt for cnt in cnts if cv2.contourArea(cnt) > 1400]\n",
    "\n",
    "# compute and draw bounding box\n",
    "c = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "boxes = []\n",
    "for i in range(len(c)):\n",
    "    rect = cv2.minAreaRect(c[i])\n",
    "    box = np.int0(cv2.boxPoints(rect))\n",
    "    if box_height(box) > fontsize * 0.5 and box_aspect_ratio(box) <= 1.1:\n",
    "        # text boxes should be short and wide\n",
    "        boxes.append(box)\n",
    "        cv2.drawContours(canvas, [box], -1, 0, 3)\n",
    "\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 20.0) \n",
    "plt.imshow(canvas, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coordinates of the boxes are listed in the array `boxes`. To extract a certain box, simply do the following perspective transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = four_point_transform(canvas.copy(), boxes[10])\n",
    "plt.imshow(roi, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Status up to this step: \n",
    "- Image0: stamp obscures line border\n",
    "- Image1: OK!\n",
    "- Image2: One false positive near paper border\n",
    "- Image3: Two False positives near paper border. Stamp obscures multiple line\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem pretty good at this stage. The final results depend on whether tesseract is more susceptible to false positives (returning a box containing only artifacts but no characters) or false negatives (missing to detect and box certain characters). This would require knowledge of the entire pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Got stamps?\n",
    "One particular problem we observe so far is that sometimes official stamps/seals overlap with the text area, and the above algorithm would return a box containing multiple lines of characters, as in `Images0` and `Image3`. This may or may not be a problem depending on the OCR algorithm. In case we would like to return boxes with at most one line of characters, we can proceed to perform the following delineation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = clean_canvas.copy()\n",
    "canvas1 = clean_canvas.copy()\n",
    "oversized_boxes = []\n",
    "old_boxes = []\n",
    "\n",
    "for box in boxes:\n",
    "    # Only inspect boxes with height larger than twice the fontsize\n",
    "    # otherwise remove the box and its contents\n",
    "    if box_height(box) <= 2 * fontsize:\n",
    "        old_boxes.append(box)\n",
    "        cv2.fillPoly(canvas1, [box], 255)\n",
    "        cv2.fillPoly(canvas, [box], 255)\n",
    "    else:\n",
    "        oversized_boxes.append(box)\n",
    "for box in oversized_boxes:\n",
    "    cv2.drawContours(canvas1, [box], -1, 0, 3)\n",
    "        \n",
    "plt.imshow(canvas1, cmap='gray')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a specific example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for box in oversized_boxes[:1]:\n",
    "    roi = four_point_transform(canvas.copy(), box)\n",
    "    plt.imshow(roi, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delineate_flag = 1\n",
    "image = 255 - canvas\n",
    "\n",
    "\n",
    "# morph\n",
    "struct_elem = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 1))\n",
    "image = cv2.dilate(image.copy(), struct_elem, iterations=2)\n",
    "delineated = image.copy()\n",
    "\n",
    "if delineate_flag:\n",
    "    profile = np.sum(image, axis=1)\n",
    "    profile = (profile / np.max(profile) * 255).astype(np.uint8)\n",
    "    profile_img = np.array([profile, profile])\n",
    "    minima_window = cv2.adaptiveThreshold(profile_img, 255, \n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 51, 10)\n",
    "    minima_window = minima_window[1, :]\n",
    "\n",
    "    x1 = np.where(np.diff(minima_window.astype(np.float)) > 0)[0]\n",
    "    x2 = np.where(np.diff(minima_window.astype(np.float)) < 0)[0]\n",
    "    # clean border area\n",
    "    if x1[0] > x2[0]:\n",
    "        x2 = x2[1:]\n",
    "    if x1[-1] > x2[-1]:\n",
    "        x1 = x1[1:]\n",
    "    assert len(x1) == len(x2)\n",
    "\n",
    "    minima = []\n",
    "    for i in range(len(x1)):\n",
    "        if np.min(profile[x1[i]:x2[i]]) > 0:\n",
    "            minima.append(np.argmin(profile[x1[i]:x2[i]]) + x1[i])\n",
    "    for pt in minima:\n",
    "        delineated[pt-5:pt+5, :] = 0\n",
    "\n",
    "    \n",
    "plt.imshow(np.hstack((image, delineated)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = clean_canvas.copy()\n",
    "\n",
    "# find contours\n",
    "im2, cnts, hierarchy = cv2.findContours(delineated.copy().astype(np.uint8), \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = [cnt for cnt in cnts if cv2.contourArea(cnt) > 1400]\n",
    "\n",
    "# compute and draw bounding box\n",
    "c = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "new_boxes = []\n",
    "for i in range(len(c)):\n",
    "    rect = cv2.minAreaRect(c[i])\n",
    "    box = np.int0(cv2.boxPoints(rect))\n",
    "    if box_height(box) > fontsize * 0.5:\n",
    "        new_boxes.append(box)\n",
    "\n",
    "# combining the old and new boxes\n",
    "boxes = old_boxes + new_boxes\n",
    "for box in boxes:\n",
    "    cv2.drawContours(canvas, [box], -1, 0, 3)\n",
    "\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 20.0) \n",
    "plt.imshow(canvas, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Status up to this step: \n",
    "- Image0: Some false positives caused by residuals of stamps.\n",
    "- Image1: OK!\n",
    "- Image2: One false positive near paper border\n",
    "- Image3: Some false positives caused by residuals of stamps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further exploration:\n",
    "Some more ideas in extracting text boxes:\n",
    "\n",
    "1. Signature boxes have a smaller black pixel density than text boxes. We can use this feature to classify if a box is a signature box or a text box. Or, we can extract some examples and train a relatively shallow neural network to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
